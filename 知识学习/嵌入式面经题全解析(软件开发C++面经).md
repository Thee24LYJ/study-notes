# 一、进程与线程

[进程与线程](进程与线程.md)
[进程与线程的一个简单解释 - 阮一峰的网络日志](https://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html)

### 1.1 基本概念

##### 1.1.1 进程、线程及其区别

- 进程(程序的一次执行过程)

**进程是程序在某个数据集合上的一次运行活动，也是操作系统进行资源分配和保护的基本单位**

- 线程

**线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位**

##### 1.1.2 多进程、多线程优缺点

[线程、进程、多线程、多进程 和 多任务 小结\_8 线程的缺点-CSDN 博客](https://blog.csdn.net/zaishuiyifangxym/article/details/89415155)

- 多进程优缺点

> 优点：
> (1) 封闭性和可再现性
> (2) 程序并发执行和资源共享
>
> 缺点：
> (1) 进程切换速度慢
> (2) 进程间内存无法共享，进程间通信也较为麻烦

- 多线程优缺点

> 优点：
> (1) 线程共享进程内存空间，线程创建花费空间小，切换速度快
> (2) 线程间通信方便快捷
>
> 缺点：
> (1) 频繁调度，上下文切换增加系统开销
> (2) 编写、调试代码困难(线程同步)，信号支持不佳

##### 1.1.3 选择使用进程还是线程

- 频繁创建销毁的优先用线程
- 进行大量计算的优先使用线程
- 强相关的处理用线程，弱相关的处理用进程

##### 1.1.4 多进程、多线程同步方式

- 多进程同步

管道、信号量、信号、消息队列、共享内存、socket

- 多线程同步

锁、信号量、信号、屏障

##### 1.1.5 进程的空间模型

虚拟空间地址从低到高：代码段->数据段->堆->支持库映射段->栈->内核空间

##### 1.1.6 进程线程的状态转换图、阻塞和就绪条件

- 三状态转换图、五状态转换图
- 阻塞：运行态进程由于需要等待像 I/O 申请等事件完成而进入阻塞态
- 就绪：刚创建好的进程默认就绪态；缺少 CPU 时间片的运行态会进入就绪态；阻塞态的事件完成后进入就绪态

##### 1.1.7 父子进程关系及区别

子进程在 Linux 上使用 fork()从父进程创建而来，几乎复制了父进程的所有信息，比如 UID&GID、环境变量、打开的文件等等，但像 PID、父进程加锁及挂起的信号等信息不会继承过来

##### 1.1.8 进程上下文和中断上下文

- 进程上下文：进程执行时，CPU 所有寄存器的值、进程状态及堆栈中的信息
- 中断上下文：硬件的中断信号使内核调用中断处理程序进入内核空间时，传递给内核的硬件信息、参数及被中断进程的相关环境

##### 1.1.9 一个进程最多可以创建的线程数

- 该问题中最多能创建的线程数与进程的虚拟内存空间大小和系统参数限制

### 1.2 并发、同步异步、互斥、阻塞非阻塞

##### 1.2.1 线程同步和互斥

- 线程同步：线程间存在依赖关系，线程 B 需要等待线程 A 执行完毕后才能继续执行
- 线程互斥：线程间对同一临界资源实现安全访问，同一时刻只能有一个线程通过竞争抢占到对该资源的访问，其他线程此时均不能访问该资源

##### 1.2.2 线程同步与阻塞的关系，同步一定阻塞吗？阻塞一定同步吗？

[一文为你讲解清楚并发，同步，异步，互斥，阻塞，非阻塞-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/1829301)

- 线程同步是一个过程，线程阻塞是线程的一种状态
- 线程同步不一定发生阻塞，线程同步的时候，需要协调推进速度，只有当访问同一资源出现互相等待和互相唤醒的时候才会发生阻塞。而阻塞了一定是同步，后访问的等待获取资源，线程进入阻塞状态，借以实现多线程同步的过程

##### 1.2.3 同步/异步、并发、互斥、阻塞/非阻塞

- 同步执行：顺序执行，执行完一个任务后再接着执行下一个任务(需要等待、协调运行)
- 异步执行：任务彼此独立，不用在等待某个任务完成后才继续执行其他任务)(PS：异步执行是最终目的，而线程是异步执行的一种实现方式)

- 线程同步：同一个资源当一个线程正在访问时，其他线程需要等待它访问结束才能访问该资源(顺序访问)；线程间存在依赖关系
- 线程互斥：与线程同步类似，但线程互斥无法控制线程对资源的访问顺序(无序访问)

[一文搞懂程序、进程、线程、并发、并行、高并发的概念](https://blog.csdn.net/Long_xu/article/details/135730509)

- 并发：一个系统能同时处理多个任务(将一个处理器按照时间片分给不同程序执行)
- 并行：系统同时能执行多个任务且每个任务都是在不同处理器核心上执行(真正意义上的同时执行)

- 阻塞：等待子函数执行结束主函数才会继续往下执行
- 非阻塞：不等待子函数执行结束就返回，主函数继续往下执行

### 1.3 孤儿进程、僵尸进程和守护进程

##### 1.3.1 相关概念

- 孤儿进程：父进程不等待子进程就提前结束，此时的子进程被称为孤儿进程
- 僵尸进程：子进程结束后，父进程没对其进行处理(调用 wait()或 waitpid()获取子进程状态信息)时，此时的子进程就被称为僵尸进程；若父进程直到结束都未对该子进程进程处理，那么这个僵尸进程会被 init 进程领养变为孤儿进程；若父进程处于死循环，那这个僵尸就会一直占用着对应的进程号等资源
- 守护进程：处于后台运行、长期存在的进程，随系统启动而启动、系统关闭而结束

##### 1.3.2 如何创建守护进程

参见[1.7.3 守护进程](进程与线程.md#1.7.3%20守护进程)

##### 1.3.3 如何正确处理僵尸进程

- 杀掉该僵尸进程的父进程
- 在父进程中对子进程结束时发出的 SIGCHLD 信号调用 wait()或 waitpid()函数进行 chuli

# 二、C/C++高频知识点

### 2.1 C 与 C++间的区别

##### 2.1.1 new 和 malloc 区别

参见[C&C++ 内存分配](C&C++%20内存分配.md)

- new 除分配内存空间外还会对该内存空间进行初始化
- new 返回指向已分配内存空间的指针是对应对象类型的指针，而不是像 malloc 返回 void\*
- new 分配内存失败会抛出 bad_alloc 异常，malloc 则返回 NULL 指针

##### 2.1.2 malloc 的底层实现

malloc 底层实现主要是通过 brk()和 mmap 分配内存的，详情见[1.1.3 malloc 底层实现内存分配方式](C&C++%20内存分配.md#1.1.3%20malloc%20底层实现内存分配方式)

##### 2.1.3 只有 1G 内存的计算机中能否使用 malloc 分配 1.2G 内存空间？

是有可能分配成功的，malloc 分配内存是想程序进程的虚拟空间中申请内存，与实际物理内存没有直接关系，后面程序运行用到的物理内存由操作系统完成映射

##### 2.1.4 指针与引用的异同，如何相互转换

详见[指针与引用](指针与引用.md)

指针和引用之间使用解引用(\*)和取地址(&)运算符实现指针和引用的相互转换

##### 2.1.5 C 语言内存分配方式、程序内存空间分布

- 内存分配方式
  - 分配自**静态存储区**：分配的内存在编译期间就确定，程序运行结束后才会释放(全局变量和 static 变量)
  - 分配自**栈**：编辑器自动分配和释放(函数实参、局部变量等)
  - 分配自**堆**：程序员手动分配和释放，未手动释放程序结束时**可能**由操作系统回收
- 程序内存空间分布(参见[1.4 进程空间分布](进程与线程.md#1.4%20进程空间分布))
  - 栈：临时变量存储，自动分配与释放(操作方式类似于数据结构中的栈)
  - 堆：动态内存存储，手动分配与释放(与数据结构中的堆不同，分配方式类似于数据结构中的链表)
  - BSS 段(未初始化数据)
  - Data 段(初始化后的数据)
  - Text 段(程序段)：程序代码在内存中的映射

Text、BSS 和 Data 段在编译时就决定了该程序进程将会占用的虚拟空间大小

##### 2.1.6 extern "C"作用

主要用在 C 和 C++混合开发的项目中，避免由于编译 C 与 C++函数时的处理不同导致链接失败

详见[extern 关键字](extern关键字.md)

##### 2.1.7 头文件中的声明可以使用 extern 进行声明，而在对应源文件中进行定义(**多次声明，一次定义**)

##### 2.1.8 函数参数压栈顺序

详见[函数调用](函数调用.md)

![](https://img2023.cnblogs.com/blog/2883666/202308/2883666-20230816142808449-1354010411.png)

##### 2.1.9 重写 memcpy()函数

详见[memcpy()函数](<memcpy()函数.md>)

主要是地址重叠问题(向前重叠和向后重叠)

##### 2.1.10 数组存放位置

见[深入理解 C 语言数组与内存分配-CSDN 博客](https://blog.csdn.net/weixin_44793395/article/details/106292650)

按照数组定义方式的不同而不同，如果数组定义为全局变量，则存储在 data 段或 bss 段；若定义为局部变量，则存储在栈区；若使用 new 定义则存储在堆区(==定义在函数内部时的局部数组时，数组的大小可以使用变量；但使用 static 进行修饰的函数内部的局部数组或者是全局的数组，数组大小不可使用变量==)

##### 2.1.11 struct 和 class 的区别

详见[struct 和 class](struct和class.md)

- struct 默认访问权限为 public，class 默认访问权限为 private
- struct 中成员函数操作较为简单，class 成员函数操作复杂

##### 2.1.12 char 和 int 的转换

- [C/C++ int 和 char 相互转换-猿说编程](https://www.codersrc.com/archives/11297.html)
- [C 学习笔记：char 与 int 互转 - mrcn - 博客园](https://www.cnblogs.com/mrcn/p/cpp-inttochar.html)

- char --> int

```cpp
// 方式1
char cnum = '1';
int inum = cnum - 48;
// 方式2
#include<stdlib.h>

/*
*描述：将一个char类型转为整数
*
*参数：
* [in] string：字符串类型
*
*返回值：返回char类型对应的整数
*/
int atoi(char *string);
```

- int --> char

```cpp
// 方式1
int inum = 1;
char cnum = inum + 48;
// 方式2
#include<stdlib.h>

/*
*描述：将一个整数转为char类型
*
*参数：
* [in] value：整数类型
* [in] string：字符串类型
* [in] radix：整数类型，转换后的进制类型，可以转为二进制/八进制/十六进制
*
*返回值：指向string这个字符串的指针
*/
char *itoa(int value,char *string,int radix);
```

##### 2.1.13 static 的用法

详见[static 关键字](static关键字.md)

```cpp
static int static_int = 1;
static void func();
```

##### 2.1.14 const 常量与 define 的区别(编译阶段、安全性、内存占用等)

详见[二、 define 与 const 常量区别](C&C++基础知识总结.md#二、%20define%20与%20const%20常量区别)

- const 在编译阶段处理，\#define 在预处理阶段处理
- const 会进行类型检查，\#define 不会进行类型检查
- const 会分配存储空间，\#define 不会分配存储空间

##### 2.1.15 volatile 作用和用法

[C/C++ 中 volatile 关键字详解 | 菜鸟教程](https://www.runoob.com/w3cnote/c-volatile-keyword.html)
[volatile 关键字的作用和应用场景【面试备用】-CSDN 博客](https://blog.csdn.net/qq_39486027/article/details/113786920)

- 关键词 volatile 表示使用它声明的变量可以被某些编译器未知因素更改，如操作系统、硬件和其他线程等，当使用 volatile 修饰变量时，编译器对该变量不会进行优化，确保每次访问该变量时都重新从内存中读取数据而非 CPU 寄存器
- 由于访问寄存器速度快于内存，所以编译器一般会进行优化减少对内存的读取，这样就可能导致读取到脏数据

##### 2.1.16 C/C++中变量作用域

详见[变量作用域分类](变量作用域分类.md)

- 全局作用域
- 局部作用域

##### 2.1.17 C++中的类型转换机制

详见[类型转换](类型转换.md)

- 编译阶段转换
  - static_cast
  - const_cast
  - reinterpret_cast
- 运行时转换：dynamic_cast

### 2.2 封装、继承与多态

详见[类的继承](类的继承.md)

##### 2.2.1 继承与虚继承

##### 2.2.2 多态类的内存布局

##### 2.2.3 派生类如何调用基类的同名函数和成员变量

添加基类作用域显示调用基类同名函数和成员变量

```cpp
class A
{
public:
	int i = 0;
};

class B : public A
{
public:
	int i = 10;

	void func()
	{
		cout << i << endl;
		cout << A::i<<endl;
	}
};
```

##### 2.2.4 多态实现的三个条件及其实现原理

详见：[C++ 多态机制](C++%20多态机制.md)

- 多态实现条件
  - 虚函数 virtual
  - 虚函数重写/覆盖
  - 基类指针或引用的对象调用虚函数
- 多态实现原理(根据虚函数表确定需要调用函数的地址)
  函数调用时进入到“基类”中去，找到对应虚函数表调用对应函数，若是基类的函数则调用基类的，否则调用派生类的

##### 2.2.5 拷贝构造函数

详见[深拷贝与浅拷贝](深拷贝与浅拷贝.md)

- 拷贝构造函数-深浅拷贝：编译器默认生成的拷贝构造函数为浅拷贝，自定义拷贝构造函数一般为深拷贝
- 拷贝构造函数及用途：用于从一个对象数据生成另一个对象，两个对象完全独立
- 自定义拷贝构造函数时机：类中含有指针成员变量时则需要自定义靠包构造函数实现深拷贝，否则编译器生成的默认拷贝构造函数只是简单拷贝指针成员导致其内存空间相同

##### 2.2.6 析构函数可以抛出异常吗？

详见[二、析构函数(Destructor)](<构造函数与析构函数.md#二、析构函数(Destructor)>)

构造函数无论何时都是可以抛出异常的
析构函数不推荐抛出异常，原因如下：

- 若析构函数抛出异常，那么抛出异常之后的代码不会执行，可能存在资源泄露问题
- 通常异常发生时，C++机制会调用已有对象的析构函数来释放资源，若析构函数本身也抛出异常，会造成程序崩溃

##### 2.2.7 调用拷贝构造函数的三种情况

详见[1.3 拷贝构造函数](构造函数与析构函数.md#1.3%20拷贝构造函数)

- 使用一个对象初始化另一个对象
- 函数形参为类对象(不是类对象指针或引用)
- 函数返回值为类对象值的形式

##### 2.2.8 析构函数一般写成虚函数的原因

详见[2.3 虚析构函数](C++%20多态机制.md#2.3%20虚析构函数)

确保当释放实际指向派生类的基类指针或引用时，派生类对象也能正确释放其资源

##### 2.2.9 构造函数为什么一般不定义为虚函数

- 存储空间角度：虚函数对应一个 vtable，vtable 存储于对象的内存空间：若构造函数是虚的，则需要通过 vtable 来调用，若对象还未实例化，即内存空间还没有，无法找到 vtable
- 使用角度：虚函数主要用于在信息不全的情况下，能使重载的函数得到对应的调用，构造函数本身就是要初始化实例，那使用虚函数就没有实际意义
- 从实际含义上看，在调用构造函数时还不能确定对象的真实类型（因为子类会调父类的构造函数）；而且构造函数的作用是提供初始化，在对象生命期只执行一次，不是对象的动态行为，也没有太大的必要成为虚函数

##### 2.2.10 纯虚函数

[c++虚函数与纯虚函数的理解及使用场合 - hellogiao1 - 博客园](https://www.cnblogs.com/hellogiao1/p/14899426.html)

- 纯虚函数代表基类函数未被实现，需要派生类对其重新定义
- 定义纯虚函数目的是实现一个接口，继承该类的派生类必须实现该函数，含有纯虚函数的类称为抽象类，抽象类不能实例化

```cpp
class A
{
public:
	virtual void func() = 0;
}
```

##### 2.2.111 静态绑定与动态绑定

详见：[一、多态性](C++%20多态机制.md#一、多态性)

- 静态绑定：通过函数重载和模板在编译期实现绑定
- 动态绑定：通过虚函数和继承在运行时实现绑定

##### 2.2.12 C++构造函数分类

详见[构造函数与析构函数](构造函数与析构函数.md)

- 默认构造函数
- 普通构造函数
- 拷贝构造函数
- 移动构造函数

##### 2.2.13 重写、重载和覆盖的区别

详见[1.3 重载、重写(覆盖)与隐藏](<C++%20多态机制.md#1.3%20重载、重写(覆盖)与隐藏>)

- 重写：继承体系中派生类重写基类中 virtual 修饰的同名且形参相同的函数
- 重载：同类中相同函数名和返回类型但形参不同
- 隐藏：派生类中屏蔽掉基类中的函数名相同的函数

```cpp
class A
{
public:
	virtual func();
	// 函数重载 func1()与func1(int a)
	void func1();
	void func1(int a);

	void func2();
};

class B : public A
{
public:
	// 函数重写/覆盖 B::func()覆盖 A::func()
	virtual func();
	// 函数隐藏 B::func2()隐藏 A::func2()
	void func2();
}
```

##### 2.2.14 成员初始化列表

- [窥视 C++细节-为什么成员初始化列表更快-CSDN 博客](https://blog.csdn.net/qiuguolu1108/article/details/114800002)
- [成员初始化列表的概念，为什么用它会快一些？-CSDN 博客](https://blog.csdn.net/salmonwilliam/article/details/114259002)
- [《逆袭进大厂》第二弹之 C++进阶篇 59 问 59 答(4W 字超强汇总)](https://zhuanlan.zhihu.com/p/349967745)

```cpp
class A
{
public:
	// 成员初始化列表
	A(int t) : a(t){}
private:
	int a;
};

class B
{
public:
	// 普通初始化
	B(int t)
	{
		b = A(t);
	}
	// 成员初始化
	B(int t) : b(t);
private:
	A b;
};
```

- 赋值初始化，通过在函数体内进行赋值初始化，该方式是在所有数据成员分配内存空间后才执行函数体中的代码
- 列表初始化，在冒号后使用初始化列表进行初始化，列表初始化是给数据成员分配内存空间时就进行初始化，此时构造函数体还未执行
- 待初始化成员是类
  - 不采用成员初始化列表而放到构造函数体中初始化：先执行一次默认构造函数初始化 b ，再执行一次有参构造函数初始化 A(t)，再执行一次赋值运算符将 A(t)赋值给 b，最后执行一次析构函数释放 A(t)
  - 采用成员初始化列表：直接调用有参数的构造函数

##### 2.2.15 如何避免编译器进行隐式类型转换

详见[十二、explicit 关键字](C&C++基础知识总结.md#十二、explicit%20关键字)

使用 explicit 声明构造函数需进行显示调用而非隐式调用

# 三、网络编程

详见：[TCP 与 UDP](TCP与UDP.md)

### 3.1 TCP 与 UDP

##### 3.1.1 TCP 与 UDP 的区别

|            |               TCP                |            UDP             |
| :--------: | :------------------------------: | :------------------------: |
|   连接性   |             面向连接             |         面向无连接         |
| 传输可靠性 | 保证可靠传输(流量和拥塞控制实现) |       不保证可靠传输       |
|  传输方式  |            面向字节流            |          面向报文          |
| 连接对象数 |            点对点通信            |      单播、多播和广播      |
|  首部开销  |         首部 20~60 字节          |     首部开销仅 8 字节      |
|  适用场景  |   高可靠传输应用场景(文件传输)   | 实时应用(视频会议、直播等) |

##### 3.1.2 TCP 与 UDP 的优缺点

- TCP 优缺点
  - 优点：可靠性传输
  - 缺点：效率低，占用资源高
- UDP 优缺点
  - 优点：效率高
  - 缺点：不可靠性传输

##### 3.1.3 TCP 和 UDP 的适用场景

- TCP：需要高可靠性传输的应用
- UDP：实时应用

##### 3.1.4 TCP 为什么可以实现可靠连接

- 滑动窗口
- 超时重传
- 流量控制
- 拥塞控制

##### 3.1.5 典型网络模型

[三种网络模型（OSI 七层参考模型、TCP/IP 参考模型、五层参模型）](https://blog.csdn.net/weixin_44417441/article/details/113769242)

- OSI 七层参考模型
  - 应用层
  - 会话层
  - 表示层
  - 传输层
  - 网络层
  - 数据链路层
  - 物理层
- TCP/IP 四层参考模型
  - 应用层
  - 传输层
  - 网络层
  - 网络接口层
- 五层参考模型
  - 应用层
  - 传输层
  - 网络层
  - 数据链路层
  - 物理层

##### 3.1.6 http 1.1 和 http 1.0 的区别

[面试常问：HTTP 1.0 和 HTTP 1.1 有什么区别？ - JavaGuide - 博客园](https://www.cnblogs.com/javaguide/p/16593084.html)

1. **连接方式** : HTTP 1.0 为短连接，HTTP 1.1 支持长连接。
2. **状态响应码** : HTTP/1.1 中新加入了大量的状态码，光是错误响应状态码就新增了 24 种。比如说，`100 (Continue)`——在请求大资源前的预热请求，`206 (Partial Content)`——范围请求的标识码，`409 (Conflict)`——请求与当前资源的规定冲突，`410 (Gone)`——资源已被永久转移，而且没有任何已知的转发地址。
3. **缓存处理** : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
4. **带宽优化及网络连接的使用** :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
5. **Host 头处理** : HTTP/1.1 在请求头中加入了`Host`字段。

##### 3.1.7 URI 和 URL 的区别

- URL(统一资源定位符) --> 标识和定位互联网资源
  - 网址，例如https://www.baidu.com/
  - 完整定义：协议类型://登录信息(认证)@服务器地址:端口号/带层次的文件路径?查询字符串#片段标识符
- URL(统一资源标识符) --> 标识互联网资源
  - 某个网络协议方案表示的资源定位标识符
- URL 是一个具体的概念，URI 是一个抽象的概念
- URL 是 URI 的子集

### 3.2 三次握手和四次挥手

[计算机网络——TCP 的三次握手与四次挥手（超详细） - 特务依昂 - 博客园](https://www.cnblogs.com/tuyang1129/p/12435772.html)

##### 3.2.1 为什么是三次握手

- 客户端向服务器发送建立连接的 TCP 报文(SYN 报文段)
- 服务器向客户端发送允许连接的 TCP 报文(SYN ACK 报文段) -> 可分为两个包发送
- 客户端向服务器发送连接建立的确认报文(SYN ACK 报文段)

##### 3.2.2 为什么三次握手中客户端需要在接收到服务器允许连接的 TCP 报文后还需要再发送一次确认？可以二次握手吗？

- 说法 1：客户端和服务器的握手过程不仅是互相确认是否可达，更重要的是同步，第一次握手客户端发送报文序号给服务器，第二次握手服务器发送报文序号给客户端，第三次握手是客户端告诉服务器，客户端接收到服务器报文序号，完成同步操作，可以开始传输数据(若没有第三次握手，服务器将无法保证客户端接收到了自己的`SYNACK`报文段，若此时`SYNACK`报文段丢失，客户端不知道服务器的初始序号，将无法处理之后到达客户端的数据)
- 说法 2：若只有两次握手，当客户端第二次发送的 SYN 报文被服务器收到并完成后续的 TCP 建立过程；第一次发送 SYN 报文才到达服务器，这时服务器会再次分配资源并维持 TCP 连接，导致服务器资源的浪费

##### 3.2.3 为什么服务器易受到 SYN 攻击

[SYN 泛洪攻击详解 - 贾维斯 Echo - 博客园](https://www.cnblogs.com/taoxiaoxin/p/13974351.html)

- SYN 攻击利用 TCP 三次握手机制，攻击方通过利用伪造的 IP 地址向服务器发送请求，而服务器发送的 SYNACK 报文段无法到达目的地，导致服务器在等待关闭这个连接过程中持续消耗资源，当存在成千上万的 SYN 攻击连接时导致服务器资源被耗尽，从而实现攻击的目的
- 服务器端资源分配在二次握手时完成，客户端资源分配在三次握手时完成

##### 3.2.4 为什么客户端四次挥手最后在 TIME-WAIT 装填需要等待 2MSL

- 当客户端接收到服务器发送的`FIN`报文后（第三次挥手），会回送一条确认报文（第四次挥手），但是，客户端并不知道这条确认报文是否可以顺利到达服务器。若这条确认报文在传送到服务器的过程中损坏、丢失或超时，将引起服务器重新发送`FIN`报文，客户端接收到后，将需要再次发送一条确认报文，直到服务器正确接收。但是，客户端发送确认报文后，立刻释放资源，将导致无法处理重传的`FIN`报文，所以客户端需要等待一段时间，直到确认没有出现上述情况出现再释放资源
- 四次挥手完成后，理论上已经断开了连接，但是这不代表之前通过这条连接发送的所有数据都处理完毕了，有些可能还在网络中传输。若在四次挥手后，立即释放客户端的资源，然后客户端立即以同一个源端口，向服务器的同一个目的端口再次建立一个`TCP`连接，这个连接和上一个的 源端口+源`IP`+目的端口+目的`IP`  都一模一样，此时将会产生问题。若上一次连接遗留在网络中的报文此时到达，将会被当做新连接传输的数据处理，于是可能会产生一些不可预估的错误。所以，客户端在断开连接后，需要等待一段时间，直到网络中遗留的数据都死掉，才释放资源，而在资源没有被释放前，是不允许建立一个 源端口+源`IP`+目的端口+目的`IP`  都一模一样的`TCP`连接的（因为`TCP`套接字由这四部分标识）

##### 3.2.5 为什么建立连接时三次握手，关闭连接时四次挥手

- TCP 建立连接时需要三次握手原因见[3.2.2 为什么三次握手中客户端需要在接收到服务器允许连接的 TCP 报文后还需要再发送一次确认？可以二次握手吗？](#3.2.2%20为什么三次握手中客户端需要在接收到服务器允许连接的%20TCP%20报文后还需要再发送一次确认？可以二次握手吗？)
- TCP 关闭连接时需要四次挥手原因：
  - 理论上，断开连接只需要两次挥手(其中一方请求断开连接，另一方确认即可)，但由于 **TCP 连接时全双工**的，因此需要客户端和服务器双方各自发起一次断开连接请求，另一方确认
  - 关闭连接时，服务器收到客户端的 FIN 报文时，仅标识客户端不再发送数据了但是服务器还能接收数据，且服务器也未必把全部数据都发送给对方了，所以服务器可以立即关闭，也可以将全部数据发送给客户端后，再发送 FIN 报文给对方来表示同意关闭连接

# 四、常见算法

### 4.1 排序算法

##### 4.1.1 各种排序算法的时间空间复杂度和稳定性

稳定性：待排序的序列中存在多个相同的值，那么排序后这些相同值的相对位置不改变，则称该排序算法是稳定的，否则称为不稳定的

见[七、排序算法](数据结构与算法知识点.md#七、排序算法)

- 平均时间复杂度
  - $O(n^2)$：冒泡排序、选择排序、插入排序
  - $O(n*log_2n)$：快速排序、堆排序、归并排序、希尔排序
- 空间复杂度
  - $O(1)$：冒泡排序、选择排序、插入排序、堆排序、希尔排序
  - $O(log_2n)$：快速排序
  - $O(n)$：归并排序
- 稳定性
  - 不稳定：快速排序、堆排序、希尔排序、选择排序 --> **快选堆希**
  - 稳定：冒泡排序、插入排序、归并排序、计数排序、桶排序 --> **插冒归计桶**

---

- 插入排序
  - 直接插入排序算法
  - 希尔排序算法
- 选择排序
  - 选择排序算法
  - 堆排序算法
- 交换排序
  - 冒泡排序算法
  - 快速排序算法
- 归并排序
  - 归并排序算法

##### 4.1.2 各种排序算法什么时候有最好情况和最坏情况

各种排序算法的最好和最坏情况的资料同上
快速排序最坏情况退化为冒泡排序，需要比较$\frac{n*(n-1)}{2}$次

##### 4.1.3 冒泡排序算法

详见[冒泡排序算法](冒泡排序算法.md)

连续比较相邻元素(从左到右/从右到左)实现冒泡排序

##### 4.1.4 选择排序算法

详见[选择排序算法](选择排序算法.md)

从左到右/从右到左，找到未排序元素区间最小值，再添加到已排序元素区间末尾

##### 4.1.5 插入排序算法

详见[插入排序算法](插入排序算法.md)

将待排序数据与已排序数据进行对比，插入正确的位置(手动整理一副牌)

##### 4.1.6 希尔排序算法

详见[希尔排序算法](希尔排序算法.md)

希尔排序是对直接插入排序的优化，主要是将原本待排序序列分割为多个子序列先进行排序(子序列增量为$t_i$)，等子序列增量变为 1 时再进行一次直接插入排序实现希尔排序整体流程

##### 4.1.7 归并排序算法

详见[归并排序算法](归并排序算法.md)

归并排序算法先将待排序序列递归划分为左右子序列，分别对其进行排序合并

##### 4.1.8 快速排序算法

详见[快速排序算法](快速排序算法.md)

类似归并排序算法，都是采用的分治策略，从序列中选出基准数据，并重新排序使该基准数据位于中间，递归地对基准值两侧的子序列进行排序

##### 4.1.9 快排算法的 partition()和归并排序算法的 merge()函数对比

参考：[快排的 partition 函数与归并的 merge 函数 - CSDN 文库](https://wenku.csdn.net/answer/d6d1ae00e61d424a95b65a2c7fac8f27)

- partition()函数：将序列中的元素分为两个部分，一部分比随机选取的基准数小，一部分比基准数大(基准数在中间)
- merge()函数：将两个已排序序列合并为一个有序序列

### 4.2 STL 标准库

##### 4.2.1 vector 与 list 的对比

见 [四、vector、list 和 deque 对比](STL库之vector、list和deque.md#四、vector、list%20和%20deque%20对比)

- vector 是连续存储的，支持高效随机访问和尾部插入删除操作，但其他位置的插入删除操作效率较低
- list 是非连续存储的，不支持随机访问，但在任何地方都能实现高效插入删除操作
- 当关心高效随机访问而不关心插入删除时推荐使用 vector，反之则推荐 list

##### 4.2.2 vector 内存增长底层实现(1.5 倍/2 倍内存扩容)

见[1.2 vector 内存分配原理](STL库之vector、list和deque.md#1.2%20vector%20内存分配原理)

##### 4.2.3 vector 和 deque 的比较

见 [四、vector、list 和 deque 对比](STL库之vector、list和deque.md#四、vector、list%20和%20deque%20对比)

- vector 与 deque 都支持随机访问，但 deque 效率不如 vector 高
- deque 类似于 vector，但是相较于 vector，能够支持在首尾插入元素

##### 4.2.4 为什么 STL 算法库中有 sort()但 list 中还需要自定义 sort()

[详细解说 STL 排序(Sort) - soqu36 - 博客园](https://www.cnblogs.com/soqu36/articles/11051534.html)
[为什么 stl 里面有 sort 函数而 list 里面还要定义一个 sort - CSDN 文库](https://wenku.csdn.net/answer/6b54b5ec8a104d50b08fb42b2edb97e3)

- STL 算法库中的 sort()用于对提供随机访问迭代器的容器元素进行排序，而 list 底层数据结构是双向链表，提供顺序访问迭代器而不提供随机访问迭代器，无法直接使用 STL 算法库中的 sort()，所以才需要自定义 sort()实现对 list 的排序
- list 中自定义 sort()采用归并排序算法，STL 算法库中的 sort()采用快速排序算法

##### 4.2.5 STL 底层数据结构

[C++ STL 容器底层数据结构的实现 - 拾月凄辰 - 博客园](https://www.cnblogs.com/FengZeng666/p/9347027.html)

|      容器类型      |                底层数据结构                |              特点              |
| :----------------: | :----------------------------------------: | :----------------------------: |
|       vector       |                    数组                    |          快速随机访问          |
|        list        |                  双向链表                  |          快速增加删除          |
|       deque        |                  两级数组                  | 快速随机访问、首尾快速增加删除 |
|       stack        |        list 或 deque 实现(封闭头部)        |            先进后出            |
|       queue        |        list 或 deque 实现(封闭头部)        |            先进先出            |
|   priority_queue   | vector 为底层容器,将其中的元素构造成堆结构 |            类似于堆            |
|        set         |                   红黑树                   |         有序，不可重复         |
|      multiset      |                   红黑树                   |          有序，可重复          |
|        map         |                   红黑树                   |         有序，不可重复         |
|      multimap      |                   红黑树                   |          有序，可重复          |
|   unordered_set    |                   哈希表                   |         无序，不可重复         |
| unordered_multiset |                   哈希表                   |          无序，可重复          |
|   unordered_map    |                   哈希表                   |         无序，不可重复         |
| unordered_multimap |                   哈希表                   |          无序，可重复          |

##### 4.2.6 使用迭代器删除元素会发生什么

[C++中利用迭代器删除元素会发生什么？-CSDN 博客](https://blog.csdn.net/YF_Li123/article/details/75003425)

- 对于顺序容器(vector、deque、list)：删除当前元素会使后面所有元素迭代器失效(除 list 外)，但 erase()删除元素时会返回下一个元素的有效迭代器
- 对于关联容器(set、map 等)：删除当前元素只会使当前元素迭代器失效，其他元素迭代器仍能正常使用

##### 4.2.7 map 实现方式及其查找效率

[C++ STL 中的 map 用红黑树实现，搜索效率是 O(lgN),为什么不像 python 一样用散列表从而获得常数级搜索效率呢？ - 雪之灵 - 博客园](https://www.cnblogs.com/gofighting/p/5438021.html)

map 的底层实现数据结构为红黑树，map 查找效率为$O(logn)$

##### 4.2.8 几种数据结构的时间复杂度

|  数据结构  |        查找         |   插入    |   删除    |
| :--------: | :-----------------: | :-------: | :-------: |
|    数组    |       $O(n)$        |  $O(n)$   |  $O(n)$   |
|  有序数组  | 二分查找：$O(logn)$ |  $O(n)$   |  $O(n)$   |
|   单链表   |       $O(n)$        |  $O(n)$   |  $O(n)$   |
| 有序单链表 |       $O(n)$        |  $O(n)$   |  $O(n)$   |
|   双链表   |       $O(n)$        |  $O(n)$   |  $O(n)$   |
| 有序双链表 |       $O(n)$        |  $O(n)$   |  $O(n)$   |
|   二叉树   |       $O(n)$        |  $O(n)$   |  $O(n)$   |
| 二叉搜索树 |      $O(logn)$      | $O(logn)$ | $O(logn)$ |
|   红黑树   |      $O(logn)$      | $O(logn)$ | $O(logn)$ |
| 平衡二叉树 |      $O(logn)$      | $O(logn)$ | $O(logn)$ |
|   哈希表   |       $O(1)$        |  $O(1)$   |  $O(1)$   |

# 五、Linux 操作系统相关

### 5.1 Linux 系统内核

##### 5.1.1 Linux 内核组成

详见[Linux 系统内核](Linux系统内核.md)

进程管理、内存管理、虚拟文件系统、网络子系统、进程间通信

##### 5.1.2 用户空间与内核通信方式

系统调用、中断、ioctl()等方式
